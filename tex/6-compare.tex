In this chapter we will present an analysis over the five presented method on previous section. The first two analysis has focus on the complexity and performance of the algorithms. However, we are not interested only in efficient methods, our main goal was achieve an method with no information leakage against a timing side-channel attack. Hence, we demonstrate an time-variance analysis for each proposed root-finding method. After that, we present an security analysis over the algorithm. Remarking that $n = 2^m$ are the size fields, and $t$ the degree of polynomial.

\section{Complexity analysis}
In order to compare the complexity of the algorithm, we use the Big $\mathcal{O}$ notation. This asymptotic notation permits to us classify the algorithms according to their behaviour when the inputs grows. 




\begin{table}[ht]
\centering
\label{tab:complexity}
\caption{Complexity comparison}
\begin{tabular}{ll}
Method                                  &                \\ \hline
Exhaustive search                       & $\mathcal{O}(2^mt)$ \\
Permuted exhaustive                     & $\mathcal{O}(2^mt)$ \\
Linearized Polynomials                  & $\mathcal{O}(2^m)$ \\
Constant Linearized Polynomials         & $\mathcal{O}(2^m)$ \\
Berlekamp trace algorithm               & $\mathcal{O}(mt^2)$ \\
Iterative Berlekamp trace algorithm     & $\mathcal{O}(m^2t^2)$ \\
Successive resultant algorithm          & $\mathcal{O}(t^2m^3)$ \\
Constant Successive resultant algorithm & $\mathcal{O}(t^2m^3)$ \\
Rabin root finding                      & $\mathcal{O}(t^2m)$
\end{tabular}
\end{table}

As we can note, the most asymptotic efficient method was the Rabin root finding method. However, this asymptotic could not reflect the execution timing of the algorithm for parameters used in code-based schemes. This happens because the big $\mathcal{O}$ notation does not consider constants and the asymptotic complexity was for all $m$ and $t$ grater then $m_0$ and $t_0$ respectively, and the parameters used on code-based cryptosystems could be smaller then the $m_0$ and $t_0$.

\section{Performance analysis}
To present a more careful analysis, we present a execution time analysis of each presented algorithm. This comparison gives an idea of the real execution cost. All root finding method was performed over and random polynomial of degree $t$ over $\mathbb{F}_2^m$, for $t = 50$ until $t = 300$ and $n = 2^10$ to $n = 2^{18}$. For each polynomial, we take the average time of 10 executions.
 
The performance analysis was implemented in Sage\cite{sage}, since we want to measure the execution coast with different parameters, the Sage library permits to us change the field with facility to perform this analysis. We run all proposed methods in a locally Intel\textsuperscript{\tiny\textregistered} Core(TM) i$7$-$4500$U CPU @ $1.80$GHz. The source code of this attack are available on \url{https://github.com/doodomartins/root-finding/soft-factorization}. The Figure~\ref{fig:time-SRA} to Figure~\ref{fig:time-EXHA} presents the execution time for each root finding method.


\begin{figure}[!ht]
\centering
\begin{subfigure}{0.48\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{fig/charts_sra.pdf}
  \caption{Execution time comparison between different $m$ and $t$ for Successive resultant algorithm.}
  \label{fig:time-SRA}
\end{subfigure}
\begin{subfigure}{0.48\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{fig/charts_sra.pdf}
  \caption{Execution time comparison between different $m$ and $t$ for Successive resultant algorithm.}
  \label{fig:time-EXHA}
\end{subfigure}
% \begin{subfigure}{0.5\textwidth}
%   \centering
%   \includegraphics[width=1\linewidth]{fig/charts_sra.pdf}
%   \caption{Comparison between BTA-rf and \\BTA-it executions.}
%   \label{fig:sbta}
% \end{subfigure}%
% \begin{subfigure}{0.5\textwidth}
%   \centering
%   \includegraphics[width=1\linewidth]{fig/charts_sra.pdf}
%   \caption{Comparison between SRA and Safe SRA executions.}
%   \label{fig:ssra}
% \end{subfigure}%

\caption{Plots of measurements time for the five methods presented.}
\label{fig:graph}
\end{figure}

For each algorithm presented, we can observe the same behaviour on execution time. Since one of the heavy terms in the complexity was the extension $m$, because they affect the algorithm exponentially, we can note that the algorithms has a growth for each extension. Moreover, a greater $m$ will result in a fast growth of the runtime.

On the other hand, the degree of the polynomial affects linearly the execution time of the algorithm. Therefore, the execution time growth more slowly when we are increasing the degree of the polynomial. 

\section{Time variance analysis}
\input{fig/variance12.tex}
\section{Security analysis}