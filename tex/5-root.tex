As argued, the leading cause of information leakage in the decoding algorithm is the process of finding the roots of the ELP. In general, the time needed to find these roots varies, often depending on the roots themselves. Thus, an attacker who has access to the decoding time can infer these roots, and hence get the vector of errors $e$. One example of this attack are presented in Section~\ref{sec:attack}, where we perform an side-channel attack over the decryption part of a cryptosystem and we recover the secret exchange between two parts of the protocol.

Factoring a polynomial it is a well studied problem on finite fields area. More recently, with the rising of the code-based area, some works starts to deal with the factorization problem on the decoding process in order to avoid timing side-channel attacks~\cite{shoufan2009timing, bucerzan2017improved}. In our systematic review, presented on Chapter~\ref{ch:method}, we select four methods used on code-based cryptosystem to analyse and to propose modifications in theirs implementation to made then available on cryptosystems applications.

The adjustments were made in the following algorithms to find roots: exhaustive search, linearized polynomials, Berlekamp trace algorithm (BTA), and successive resultant algorithm (SRA). Also, we present the Cantor-Zassenhaus method, as it has a probabilistic algorithm that made use of an random selection of polynomials in their execution, we made an security analysis over this algorithm to evaluate their blindness on a side-channel attack scenario. The description of each algorithm are presented in the next sections and the analysis are presented on Chapter~\ref{ch:comparison}.

\section{Exhaustive search}
The exhaustive search, also called Chien Search~\cite{chien1964cyclic}, is a direct method, in which the evaluation of $f$ for all the elements in $\mathbb{F}_{2^m}$ is performed. A root is found whenever the evaluation result is zero. This method is acceptable for small fields and can be made efficient with a parallel implementation. The greatest drawback of this method it was the complexity of this algorithm, and this is the reason because their are not widely used. However, we consider that their are still relevant, it is because some NIST proposals are based on a small finite field, enabling their usage. 

Algorithm~\ref{alg:exhaustive} describes the exhaustive search. For every element in $\mathbb{F}_{2^m}$ we evaluate the polynomial and check if it was a root or not, and this method leaks information when we found a root. This is because whenever we found, i.e., $dummy = 0$, an extra operation is performed by adding the root founded on the returning list $R$. In this way, the attacker can infer from this additional time that a root was found, thus providing ways to obtain data that should be secret.

\begin{figure}[ht]
\begin{algorithm}[H]
 \KwData{$p(x)$ as univariate polynomial over $\mathbb{F}_{2^m}$ with $d$ roots, $A = [a_0, \ldots, a_{n-1}]$ as all elements in $\mathbb{F}_{2^m}$, $n$ as the length of $A$.}
 \KwResult{$R$ as a set of roots of $p(x)$.}
 $R \gets \emptyset$\;
\For{$i\gets0$ \KwTo $n-1$}{
    $dummy \gets p(A[i])$\;
   \If{$dummy == 0$}{
        $R.add(A[i])$\;
    }
}
\Return $R$\;
  \caption{Exhaustive search algorithm for finding roots of a univariate polynomial over $\mathbb{F}_{2^m}$.}\label{alg:exhaustive}
\end{algorithm}
\end{figure}

One solution to avoid this leakage is to permute the elements of vector $A$ before start the evaluation. Using this technique, an attacker can identify the extra operation, but without learning any secret information. In our case, we use the Fisher-Yates shuffle~\cite{black2005fisher} for shuffling the elements of vector $A$. In~\cite{wang2018fpga}, the authors show an implementation of the shuffling algorithm safe against timing attacks, thus we can build and exhaustive search without leak information against a side-channel attack. Algorithm~\ref{alg:exhaustive_permuted} shows the permutation of the elements and the computation of the roots.

\begin{figure}[ht]
\begin{algorithm}[H]
 \KwData{$p(x)$ as a univariate polynomial over $\mathbb{F}_{2^m}$ with $d$ roots, $A = [a_0, \ldots, a_{n-1}]$ as all elements in $\mathbb{F}_{2^m}$, $n$ as the length of $A$.}
 \KwResult{$R$ as a set of roots of $p(x)$.}
  permute$(A)$\;
 $R \gets \emptyset$\;
\For{$i\gets0$ \KwTo $n-1$}{
    $dummy \gets p(A[i])$\;
   \If{$dummy == 0$}{
        $R.add(A[i])$\;
    }
}
\Return $R$\;
 \caption{Exhaustive search algorithm with a countermeasure for finding roots of an univariate polynomial over $\mathbb{F}_{2^m}$.}
  \label{alg:exhaustive_permuted}
\end{algorithm}
\end{figure}

Using this approach, we add one extra step to the algorithm. However, this permutation blurs the sensitive information of the algorithm, making the usage of Algorithm~\ref{alg:exhaustive_permuted} slightly harder for the attacker to acquire timing leakage. For this case, we want to avoid the addition of an \texttt{else} clause adding the elements that are not a root in other list. This addition will absolutely reduce the time variance on the execution of the algorithm, but it could open a lack for cache attacks~\cite{dan2005}.


\section{Berlekamp Trace Algorithm}
Our second strategy was the classical Berlekamp factoring algorithm~\cite{berlekamp1970factoring}. Berlekamp presents an efficient algorithm to factor a polynomial, which can be used to find its roots. We call this algorithm \emph{Berlekamp trace algorithm} since it works with a 

The trace function defined as $Tr(x) = x + x^{2} + x^{2^{2}} + \dots + x^{2^{m-1}}$. It is possible to change BTA for finding roots of a polynomial $p(x)$ using $\beta = \{\beta_1, \beta_2, \ldots, \beta_m\}$ as a standard basis of $\mathbb{F}_{2^{m}}$, and then computing the greatest common divisor between $p(x)$ and $Tr(\beta_0 \cdot x)$. After that, it starts a recursion where BTA performs two recursive calls; one with the result of gcd algorithm and the other with the remainder of the division $p(x) / \gcd(p(x), Tr(\beta_i \cdot x))$. 

The base case is when the degree of the input polynomial is smaller than one. In this case, BTA returns the root, by getting the independent term of the polynomial. In summary, the BTA is a divide and conquer like algorithm since it splits the task of computing the roots of a polynomial $p(x)$ into the roots of two smalls polynomials. All this steps are describe in Algorithm~\ref{alg:bta}.


\begin{figure}[ht]
\begin{algorithm}[H]
 \KwData{$p(x)$ as a univariate polynomial over $\mathbb{F}_{2^m}$ and i.}
 \KwResult{The set of roots of $p(x)$.}
    \If{$deg(p(x)) \leq 1$}{
        \Return root of $p(x)$\;
    }
    $p_{0}(x) \gets gcd(p(x), Tr(\beta_{i}\cdot x))$\;
    $p_{1}(x) \gets p(x) / p_{0}(x)$ \;
\Return $BTA(p_{0}(x), i + 1) \cup BTA(p_{1}(x), i + 1)$\;
 \caption{Berlekamp Trace Algorithm -- $BTA(p(x), i)-rf$.}
  \label{alg:bta}
\end{algorithm}
\end{figure}

As we can see, a direct implementation of Algorithm~\ref{alg:bta} has no constant execution time. The recursive behavior may leak information about the characteristics of roots in a side-channel attack. Additionally, in our experiments, we noted that the behavior of the gcd with the trace function may result in a polynomial with the same degree. Therefore, BTA will divide this input polynomial in a future call with a different basis. Consequently, there is no guarantee of a constant number of executions. 

In order to avoid the nonconstant number of executions, here referred as $BTA-it$, we propose an iterative implementation of Algorithm~\ref{alg:bta}. In this way, our proposal iterates in a fixed number of iterations instead of calling itself until the base case. The main idea is not changed; we still divide the task of computing the roots of a polynomial $p(x)$ into two smaller instances. However, we change the approach of the division of the polynomial. Since we want to compute the same number of operations independent of the degree of the polynomial, we perform the gcd with a trace function for all basis in $\beta$, and choose a division that results in two new polynomials with approximate degree.

This new approach allows us to define a fixed number of iterations for our version of BTA. Since we always divide into two small instances, we need $t-1$ iterations to split a polynomial of degree $t$ in $t$ polynomials of degree $1$. Algorithm~\ref{alg:ibta} presents this approach.


\begin{algorithm}[ht]
 \KwData{$p(x)$ as an univariate polynomial over $\mathbb{F}_{2^m}$, $t$ as number of expected roots.}
 \KwResult{The set of roots of $p(x)$.}
    $g \gets \{p(x)\};$ \tcp{The set of polynomials to be computed}
    \For{$k \gets 0$ \KwTo $t$}{
        $current = g.pop()$\;
        Compute $candidates$ $=$ $gcd(current, Tr(\beta_{i}\cdot x))$ $\forall$ $\beta_{i}$ $\in$ $\beta$\;
        Select $p_{0}$ $\in$ $candidates$ such as $p_{0}.degree$ $\simeq$ $\frac{current}{2}$\;
        $p_{1}(x) \gets current / p_{0}(x)$ \;
        \If{$p_{0}.degree == 1$}{
            $R.add($root of $p_{0})$
        } \Else{
            $g.add(p_{0})$\;
        }
        \If{$p_{1}.degree == 1$}{
            $R.add($root of $p_{1})$
        } \Else{
            $g.add(p_{1})$\;
        }
    }
    \Return{$R\;$}
 \caption{Iterative Berlekamp Trace Algorithm -- $BTA(p(x))-it$.}
  \label{alg:ibta}
\end{algorithm}

Algorithm~\ref{alg:ibta} extracts a root of the polynomial when the variable $current$ has a polynomial with degree equal to one. If this degree is greater than one, then the algorithm needs to continue dividing the polynomial until it finds a root. The algorithm does that by adding the polynomial in a stack and reusing this polynomial in a division. 

\section{Linearized Polynomials}
The second countermeasure proposed is based on linearized polynomials. The authors in \cite{fedorenko2002finding} propose a method to compute the roots of a polynomial over $\mathbb{F}_{2^m}$, using a particular class of polynomials, called linearized polynomials. In \cite{strenzke2012fast}, this approach is a recursive algorithm which the author calls ``dcmp-rf''. In our solution, however, we present an iterative algorithm. We define linearized polynomials as follows:

\begin{definition}
A polynomial $\ell(y)$ over $\mathbb{F}_{2^m}$ is called a linearized polynomial if
\begin{equation}
    \ell(y) = \sum_i c_iy^{2^i},
\end{equation}
where $c_i \in \mathbb{F}_{2^m}$.
\end{definition}
In addition, from~\cite{truong2001fast}, we have Lemma~\ref{lemma:lin} that describes the main property of linearized polynomials for finding roots.
\begin{lemma}
\label{lemma:lin}
    Let $y \in \mathbb{F}_{2^m}$ and let $\alpha^0, \alpha^1, \ldots, \alpha^{m-1}$ be a standard basis over $\mathbb{F}_2$. If
    \begin{equation}
        y = \sum_{k=0}^{m-1} y_k\alpha^k, y_k \in \mathbb{F}_2
    \end{equation}
    and $\ell(y) =\sum_j c_jy^{2^j}$, then
      \begin{equation}
        \ell(y) = \sum_{k=0}^{m-1} y_k\ell(\alpha^k).
    \end{equation}
\end{lemma}

We call $A(y)$ over $\mathbb{F}_{2^m}$ as an affine polynomial if $A(y) = \ell(y) + \beta$ for $\beta \in \mathbb{F}_{2^m}$, where $\ell(y)$ is a linearized polynomial.

We can illustrate a toy example to understand the idea behind finding roots using linearized polynomials.
\begin{example}\label{ex:1}
Let us consider the polynomial $f(y) = y^2 + (\alpha^2+1)y + (\alpha^2 +\alpha +1)y^0$ over $\mathbb{F}_{2^3}$ and $\alpha$ are elements in $\mathbb{F}_2[x]/ x^3+x^2+1$. Since we are trying to find roots, we can write $f(y)$ as
 $$ y^2 + (\alpha^2+1)y + (\alpha^2 +\alpha +1)y^0 = 0$$
 or
\begin{equation}\label{eq:example_1}
    y^2 + (\alpha^2+1)y   = (\alpha^2 +\alpha +1)y^0
\end{equation}
We can point that on the left hand side of Equation~\ref{eq:example_1}, $\ell(y) = y^2 + (\alpha^2+1)y$ is a linearized polynomial over $\mathbb{F}_{2^3}$ and Equation~\ref{eq:example_1} can be expressed just as
\begin{equation}\label{eq:example_1_2}
    \ell(y) = \alpha^2 +\alpha +1
\end{equation}
If $y = y_2\alpha^2 + y_1\alpha + y_0 \in \mathbb{F}_{2^3}$ then, according to Lemma~\ref{lemma:lin}, Equation~\ref{eq:example_1_2} becomes
\begin{equation}\label{eq:example_1_3}
    y_2\ell(\alpha^2) + y_1\ell(\alpha) + y_0\ell(\alpha^0) = \alpha^2 +\alpha +1
\end{equation}
We can compute $\ell(\alpha^0),\ell(\alpha)$ and $\ell(\alpha^2)$ using the left hand side of Equation~\ref{eq:example_1} and we have the following values
\begin{equation}\label{eq:example_1_4}
    \begin{split}
        \ell(\alpha^0) & = (\alpha^0)^2 + (\alpha^2+1)(\alpha^0) = \alpha^2+1 + 1 = \alpha^2 \\
        \ell(\alpha) & = (\alpha)^2 + (\alpha^2+1)(\alpha) = \alpha^2 + \alpha^2+ \alpha + 1 = \alpha + 1 \\
        \ell(\alpha^2) & = (\alpha^2)^2 + (\alpha^2+1)(\alpha^2) = \alpha^4 +\alpha^4 +  \alpha^2 = \alpha^2.
    \end{split}
\end{equation}
A substitution of Equation~\ref{eq:example_1_4} into Equation~\ref{eq:example_1_3} gives us
\begin{equation}\label{eq:example_1_5}
     (y_2+y_0)\alpha^2 + (y_1)\alpha + (y_1)\alpha^0 = \alpha^2 +\alpha +1
\end{equation}
Equation~\ref{eq:example_1_5} can be expressed as a matrix in the form
\begin{equation}\label{eq:example_1_6}
    \begin{bmatrix} y_2 & y_1 & y_0 \end{bmatrix}
    \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 1 \\
    1 & 0 & 0
    \end{bmatrix}
    =
    \begin{bmatrix} 1 & 1 & 1 \end{bmatrix}.
\end{equation}
If one solves simultaneously the linear system in Equation~\ref{eq:example_1_6} then the results are the roots of the polynomial given in Equation~\ref{eq:example_1}. From Equation~\ref{eq:example_1_5}, one observes that the solutions are $y=110$ and $y=011$, which can be translated to $\alpha + 1$ and $\alpha^2 + \alpha$.
\end{example}


Fortunately, the authors in \cite{fedorenko2002finding} provide a generic decomposition for finding affine polynomials. In their work, each polynomial in the form $F(y) = \sum_{j=0}^{t} f_jy^j$ for $f_j \in \mathbb{F}_{2^m}$ can be represented as
\begin{equation}
\label{eq:f_y}
    F(y) = f_3y^3 + \sum_{i=0}^{\lceil (t-4)/5 \rceil} y^{5i}(f_{5i} + \sum_{j=0}^{3} f_{5i+2^j}y^{2^j})
\end{equation}
After that, we can summarize all the steps as Algorithm~\ref{alg:linearized}. The function ``generate($m$)'' refers to the generation of the elements in $\mathbb{F}_{2^m}$ using Gray codes, see \cite{savage1997survey} for more details about Gray codes. Algorithm~\ref{alg:linearized} presents a countermeasure in the last steps of the algorithm, i.e., we added a dummy operation for blinding if $X[j]$ is a root of polynomial $F(x)$.

\begin{figure}
\begin{algorithm}[H]
 \KwData{$F(x)$ as a univariate polynomial over $\mathbb{F}_{2^m}$ with degree $t$ and $m$ as the extension field degree.}
 \KwResult{$R$ as a set of roots of $p(x)$.}
 $\ell^k_i \gets \emptyset$; $\ell_{is} \gets \emptyset$; $A^j_k \gets \emptyset$; $R \gets \emptyset$; $dummy \gets \emptyset$\;
 \If{$f_0  == 0$}{
 $R.append(0)$\;
 }
 \For{$i\leftarrow 0$ \KwTo $\lceil (t-4)/5 \rceil$}
 {
    $\ell_i(x) \gets 0$\;
    \For{$j\gets 0$ \KwTo $3$}{
      $\ell_i(x) \gets \ell_i(x) + f_{5i+2^j}x^{2^j}$\;
      }
    $\ell_{is}[i] \gets \ell_i(x)$\;
 }
 \For{$k\gets 0$ \KwTo $m-1$}{
    \For{$i\leftarrow 0$ \KwTo $\lceil (t-4)/5 \rceil$}
    {
        $\ell^k_i \gets \ell_{is}(\alpha^k)$\;
    }

 }
 $A^0_i \gets \emptyset$\;
 \For{$i\gets 0$ \KwTo $\lceil (t-4)/5 \rceil$}{
  $A^0_i \gets f_{5i}$\;
 }

 $X \gets \text{generate}(m)$\;
 \For{$j\gets 1$ \KwTo $2^m - 1$}{
    \For{$i\gets 0$ \KwTo $\lceil (t-4)/5 \rceil$}{
        $A \gets A^{j-1}_i$\;
        $A \gets A + \ell^{\delta(X[j], X[j-1])}_i$\;
        $A^j_i \gets A$\;
    }
 }
\For{$j\gets 1$ \KwTo $2^m - 1$}{
    $result \gets 0$\;
    \For{$i\gets 0$ \KwTo $\lceil (t-4)/5 \rceil$}{
        $result = result + (X[j])^{5i}A^j_i$\;
    }
    $eval = result + f_3(X[j])^{3}$\;
    \eIf{$eval == 0$}{
        $R.append(X[j])$\;
    }{
        $dummy.append(X[j])$\;
    }
}
\Return $R$\;
 \caption{Linearized polynomials for finding roots over $\mathbb{F}_{2^m}$.}
  \label{alg:linearized}
\end{algorithm}
\end{figure}

\section{Successive Resultant Algorithm}
In \cite{petit2014finding}, the authors present an alternative method for finding roots in $\mathbb{F}_{p^m}$. Later on, the authors better explain the method in~\cite{petit2016finding}. The Successive Resultant Algorithm (SRA) relies on the fact that it is possible to find roots exploiting properties of an ordered set of rational mappings.

Given a polynomial $f$ of degree $d$ and a sequence of rational maps $K_1,\ldots, K_t$, the algorithm computes finite sequences of length $j \leq t+1$ obtained by successively transforming the roots of $f$ by applying the rational maps. The algorithm is as follows: Let $\{v_1,\ldots,v_m\}$ be an arbitrary basis of $\mathbb{F}_{p^m}$ over $\mathbb{F}_p$, then it is possible to define $m+1$ functions $\ell_0, \ell_1,\ldots, \ell_m$ from $\mathbb{F}_{p^m}$ to $\mathbb{F}_{p^m}$ such that
$$
\left \{
\begin{array}{l}
     \ell_0(z) = z\\
     \ell_1(z) = \prod_{i\in \mathbb{F}_p}\ell_0(z-iv_1)\\
     \ell_2(z) = \prod_{i\in \mathbb{F}_p}\ell_1(z-iv_2)\\
     \cdots \\
     \ell_m(z) = \prod_{i\in \mathbb{F}_p}\ell_{m-1}(z-iv_m)\\
\end{array}
\right.
$$
The functions $\ell_j$ are examples of linearized polynomials, as previously defined in Chapter~\ref{ch:math}. Our next step is to present the theorems from \cite{petit2014finding}. Check original work for the proofs.
\begin{theorem}\label{lemma_1}
\begin{itemize}
    \item[a)] Each polynomial $\ell_i$ is split and its roots are all elements of the vector space generated by $\{v_1, \ldots,v_i\}$. In particular, we have $\ell_n(z) = z^{p^m} -z$.
    \item[b)] We have $\ell_i(z)  = \ell_{i-1}(z)^p - a_i\ell_{i-1}(z)$ where $a := (\ell_{i-1}(v_i))^{p-1}$.
    \item[c)] If we identify $\mathbb{F}_{p^m}$ with the vector space $(\mathbb{F}_p)^m$, then each $\ell_i$ is a $p$-to-$1$ linear map of $\ell_{i-1}(z)$ and a $p^i$ to $1$ linear map of $z$.
\end{itemize}
\end{theorem}

From Theorem~\ref{lemma_1} and its properties, we can reach the following polynomial system:
\begin{equation}\label{eq:system_1}
    \left \{
\begin{array}{l}
    f(x_1) = 0\\
     x_j^p = a_jx_j = x_{j+1} \quad j=1,\ldots, m-1\\
     x_n^p - a_nx_n = 0
\end{array}
\right.
\end{equation}
where the $a_i \in \mathbb{F}_{p^n}$ are defined as in Theorem~\ref{lemma_1}. Any solution of this system provides us with a root of $f$ by the first equation, and the $n$ last equations together imply this root belongs to $\mathbb{F}_{p^n}$. From this system of equations,~\cite{petit2014finding} derives Theorem~\ref{lemma_2}.

\begin{theorem}\label{lemma_2}
Let $(x_1,x_2,\ldots,x_m)$ be a solution of the equations in Equation~\ref{eq:system_1}. Then $x_1 \in \mathbb{F}_{p^m}$ is a solution of $f$. Conversely, given a solution $x_1 \in \mathbb{F}_{p^m}$ of $f$, we can reconstruct a solution of all equations in Equation~\ref{eq:system_1} by setting $x_2 =x_1^p - a_1x_1$, etc.
\end{theorem}

In \cite{petit2014finding}, the authors present an algorithm for solving the system in Equation~\ref{eq:system_1} using resultants. The solutions of the system are the roots of polynomial $f(x)$. It is worth remarking that this algorithm is almost constant-time and hence we just need to protect the branches presented on it.


\section{Cantor-Zassenhaus Algorithm}
