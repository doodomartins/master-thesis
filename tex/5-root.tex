\section{Exhaustive search}
The exhaustive search is a direct method, in which the evaluation of $f$ for all the elements in $\mathbb{F}_{2^m}$ is performed. A root is found whenever the evaluation result is zero. This method is acceptable for small fields and can be made efficient with a parallel implementation. Algorithm~\ref{alg:exhaustive} describes this method.

As can be seen in Algorithm~\ref{alg:exhaustive}, this method leaks information. This is because whenever a root is found, i.e., $dummy = 0$, an extra operation is performed. In this way, the attacker can infer from this additional time that a root was found, thus providing ways to obtain data that should be secret.

\begin{figure}[ht]
\begin{algorithm}[H]
 \KwData{$p(x)$ as univariate polynomial over $\mathbb{F}_{2^m}$ with $d$ roots, $A = [a_0, \ldots, a_{n-1}]$ as all elements in $\mathbb{F}_{2^m}$, $n$ as the length of $A$.}
 \KwResult{$R$ as a set of roots of $p(x)$.}
 $R \gets \emptyset$\;
\For{$i\gets0$ \KwTo $n-1$}{
    $dummy \gets p(A[i])$\;
   \If{$dummy == 0$}{
        $R.add(A[i])$\;
    }
}
\Return $R$\;
  \caption{Exhaustive search algorithm for finding roots of a univariate polynomial over $\mathbb{F}_{2^m}$.}\label{alg:exhaustive}
\end{algorithm}
\end{figure}

One solution to avoid this leakage is to permute the elements of vector $A$. Using this technique, an attacker can identify the extra operation, but without learning any secret information. In our case, we use the Fisher-Yates shuffle~\cite{black2005fisher} for shuffling the elements of vector $A$. In~\cite{wang2018fpga}, the authors show an implementation of the shuffling algorithm safe against timing attacks. Algorithm~\ref{alg:exhaustive_permuted} shows the permutation of the elements and the computation of the roots.

\begin{figure}[ht]
\begin{algorithm}[H]
 \KwData{$p(x)$ as a univariate polynomial over $\mathbb{F}_{2^m}$ with $d$ roots, $A = [a_0, \ldots, a_{n-1}]$ as all elements in $\mathbb{F}_{2^m}$, $n$ as the length of $A$.}
 \KwResult{$R$ as a set of roots of $p(x)$.}
  permute$(A)$\;
 $R \gets \emptyset$\;
\For{$i\gets0$ \KwTo $n-1$}{
    $dummy \gets p(A[i])$\;
   \If{$dummy == 0$}{
        $R.add(A[i])$\;
    }
}
\Return $R$\;
 \caption{Exhaustive search algorithm with a countermeasure for finding roots of an univariate polynomial over $\mathbb{F}_{2^m}$.}
  \label{alg:exhaustive_permuted}
\end{algorithm}
\end{figure}

Using this approach, we add one extra step to the algorithm. However, this permutation blurs the sensitive information of the algorithm, making the usage of Algorithm~\ref{alg:exhaustive_permuted} slightly harder for the attacker to acquire timing leakage.


\section{Berlekamp Trace Algorithm}
In~\cite{berlekamp1970factoring}, Berlekamp presents an efficient algorithm to factor a polynomial, which can be used to find its roots. We call this algorithm \emph{Berlekamp trace algorithm} since it works with a trace function defined as $Tr(x) = x + x^{2} + x^{2^{2}} + \dots + x^{2^{m-1}}$. It is possible to change BTA for finding roots of a polynomial $p(x)$ using $\beta = \{\beta_1, \beta_2, \ldots, \beta_m\}$ as a standard basis of $\mathbb{F}_{2^{m}}$, and then computing the greatest common divisor between $p(x)$ and $Tr(\beta_0 \cdot x)$. After that, it starts a recursion where BTA performs two recursive calls; one with the result of gcd algorithm and the other with the remainder of the division $p(x) / \gcd(p(x), Tr(\beta_i \cdot x))$. The base case is when the degree of the input polynomial is smaller than one. In this case, BTA returns the root, by getting the independent term of the polynomial. In summary, the BTA is a divide and conquer like algorithm since it splits the task of computing the roots of a polynomial $p(x)$ into the roots of two smalls polynomials. The description of BTA algorithm is presented in Algorithm~\ref{alg:bta}.

\begin{figure}[ht]
\begin{algorithm}[H]
 \KwData{$p(x)$ as a univariate polynomial over $\mathbb{F}_{2^m}$ and i.}
 \KwResult{The set of roots of $p(x)$.}
    \If{$deg(p(x)) \leq 1$}{
        \Return root of $p(x)$\;
    }
    $p_{0}(x) \gets gcd(p(x), Tr(\beta_{i}\cdot x))$\;
    $p_{1}(x) \gets p(x) / p_{0}(x)$ \;
\Return $BTA(p_{0}(x), i + 1) \cup BTA(p_{1}(x), i + 1)$\;
 \caption{Berlekamp Trace Algorithm -- $BTA(p(x), i)-rf$.}
  \label{alg:bta}
\end{algorithm}
\end{figure}

As we can see, a direct implementation of Algorithm~\ref{alg:bta} has no constant execution time. The recursive behavior may leak information about the characteristics of roots in a side-channel attack. Additionally, in our experiments, we noted that the behavior of the gcd with the trace function may result in a polynomial with the same degree. Therefore, BTA will divide this input polynomial in a future call with a different basis. Consequently, there is no guarantee of a constant number of executions. 

In order to avoid the nonconstant number of executions, here referred as $BTA-it$, we propose an iterative implementation of Algorithm~\ref{alg:bta}. In this way, our proposal iterates in a fixed number of iterations instead of calling itself until the base case. The main idea is not changed; we still divide the task of computing the roots of a polynomial $p(x)$ into two smaller instances. However, we change the approach of the division of the polynomial. Since we want to compute the same number of operations independent of the degree of the polynomial, we perform the gcd with a trace function for all basis in $\beta$, and choose a division that results in two new polynomials with approximate degree.

This new approach allows us to define a fixed number of iterations for our version of BTA. Since we always divide into two small instances, we need $t-1$ iterations to split a polynomial of degree $t$ in $t$ polynomials of degree $1$. Algorithm~\ref{alg:ibta} presents this approach.


\begin{algorithm}[ht]
 \KwData{$p(x)$ as an univariate polynomial over $\mathbb{F}_{2^m}$, $t$ as number of expected roots.}
 \KwResult{The set of roots of $p(x)$.}
    $g \gets \{p(x)\};$ \tcp{The set of polynomials to be computed}
    \For{$k \gets 0$ \KwTo $t$}{
        $current = g.pop()$\;
        Compute $candidates$ $=$ $gcd(current, Tr(\beta_{i}\cdot x))$ $\forall$ $\beta_{i}$ $\in$ $\beta$\;
        Select $p_{0}$ $\in$ $candidates$ such as $p_{0}.degree$ $\simeq$ $\frac{current}{2}$\;
        $p_{1}(x) \gets current / p_{0}(x)$ \;
        \If{$p_{0}.degree == 1$}{
            $R.add($root of $p_{0})$
        } \Else{
            $g.add(p_{0})$\;
        }
        \If{$p_{1}.degree == 1$}{
            $R.add($root of $p_{1})$
        } \Else{
            $g.add(p_{1})$\;
        }
    }
    \Return{$R\;$}
 \caption{Iterative Berlekamp Trace Algorithm -- $BTA(p(x))-it$.}
  \label{alg:ibta}
\end{algorithm}

Algorithm~\ref{alg:ibta} extracts a root of the polynomial when the variable $current$ has a polynomial with degree equal to one. If this degree is greater than one, then the algorithm needs to continue dividing the polynomial until it finds a root. The algorithm does that by adding the polynomial in a stack and reusing this polynomial in a division. 

\section{Linearized Polynomials}
The second countermeasure proposed is based on linearized polynomials. The authors in \cite{fedorenko2002finding} propose a method to compute the roots of a polynomial over $\mathbb{F}_{2^m}$, using a particular class of polynomials, called linearized polynomials. In \cite{strenzke2012fast}, this approach is a recursive algorithm which the author calls ``dcmp-rf''. In our solution, however, we present an iterative algorithm. We define linearized polynomials as follows:

\begin{definition}
A polynomial $\ell(y)$ over $\mathbb{F}_{2^m}$ is called a linearized polynomial if
\begin{equation}
    \ell(y) = \sum_i c_iy^{2^i},
\end{equation}
where $c_i \in \mathbb{F}_{2^m}$.
\end{definition}
In addition, from~\cite{truong2001fast}, we have Lemma~\ref{lemma:lin} that describes the main property of linearized polynomials for finding roots.
\begin{lemma}
\label{lemma:lin}
    Let $y \in \mathbb{F}_{2^m}$ and let $\alpha^0, \alpha^1, \ldots, \alpha^{m-1}$ be a standard basis over $\mathbb{F}_2$. If
    \begin{equation}
        y = \sum_{k=0}^{m-1} y_k\alpha^k, y_k \in \mathbb{F}_2
    \end{equation}
    and $\ell(y) =\sum_j c_jy^{2^j}$, then
      \begin{equation}
        \ell(y) = \sum_{k=0}^{m-1} y_k\ell(\alpha^k).
    \end{equation}
\end{lemma}

We call $A(y)$ over $\mathbb{F}_{2^m}$ as an affine polynomial if $A(y) = \ell(y) + \beta$ for $\beta \in \mathbb{F}_{2^m}$, where $\ell(y)$ is a linearized polynomial.

We can illustrate a toy example to understand the idea behind finding roots using linearized polynomials.
\begin{example}\label{ex:1}
Let us consider the polynomial $f(y) = y^2 + (\alpha^2+1)y + (\alpha^2 +\alpha +1)y^0$ over $\mathbb{F}_{2^3}$ and $\alpha$ are elements in $\mathbb{F}_2[x]/ x^3+x^2+1$. Since we are trying to find roots, we can write $f(y)$ as
 $$ y^2 + (\alpha^2+1)y + (\alpha^2 +\alpha +1)y^0 = 0$$
 or
\begin{equation}\label{eq:example_1}
    y^2 + (\alpha^2+1)y   = (\alpha^2 +\alpha +1)y^0
\end{equation}
We can point that on the left hand side of Equation~\ref{eq:example_1}, $\ell(y) = y^2 + (\alpha^2+1)y$ is a linearized polynomial over $\mathbb{F}_{2^3}$ and Equation~\ref{eq:example_1} can be expressed just as
\begin{equation}\label{eq:example_1_2}
    \ell(y) = \alpha^2 +\alpha +1
\end{equation}
If $y = y_2\alpha^2 + y_1\alpha + y_0 \in \mathbb{F}_{2^3}$ then, according to Lemma~\ref{lemma:lin}, Equation~\ref{eq:example_1_2} becomes
\begin{equation}\label{eq:example_1_3}
    y_2\ell(\alpha^2) + y_1\ell(\alpha) + y_0\ell(\alpha^0) = \alpha^2 +\alpha +1
\end{equation}
We can compute $\ell(\alpha^0),\ell(\alpha)$ and $\ell(\alpha^2)$ using the left hand side of Equation~\ref{eq:example_1} and we have the following values
\begin{equation}\label{eq:example_1_4}
    \begin{split}
        \ell(\alpha^0) & = (\alpha^0)^2 + (\alpha^2+1)(\alpha^0) = \alpha^2+1 + 1 = \alpha^2 \\
        \ell(\alpha) & = (\alpha)^2 + (\alpha^2+1)(\alpha) = \alpha^2 + \alpha^2+ \alpha + 1 = \alpha + 1 \\
        \ell(\alpha^2) & = (\alpha^2)^2 + (\alpha^2+1)(\alpha^2) = \alpha^4 +\alpha^4 +  \alpha^2 = \alpha^2.
    \end{split}
\end{equation}
A substitution of Equation~\ref{eq:example_1_4} into Equation~\ref{eq:example_1_3} gives us
\begin{equation}\label{eq:example_1_5}
     (y_2+y_0)\alpha^2 + (y_1)\alpha + (y_1)\alpha^0 = \alpha^2 +\alpha +1
\end{equation}
Equation~\ref{eq:example_1_5} can be expressed as a matrix in the form
\begin{equation}\label{eq:example_1_6}
    \begin{bmatrix} y_2 & y_1 & y_0 \end{bmatrix}
    \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 1 \\
    1 & 0 & 0
    \end{bmatrix}
    =
    \begin{bmatrix} 1 & 1 & 1 \end{bmatrix}.
\end{equation}
If one solves simultaneously the linear system in Equation~\ref{eq:example_1_6} then the results are the roots of the polynomial given in Equation~\ref{eq:example_1}. From Equation~\ref{eq:example_1_5}, one observes that the solutions are $y=110$ and $y=011$, which can be translated to $\alpha + 1$ and $\alpha^2 + \alpha$.
\end{example}


Fortunately, the authors in \cite{fedorenko2002finding} provide a generic decomposition for finding affine polynomials. In their work, each polynomial in the form $F(y) = \sum_{j=0}^{t} f_jy^j$ for $f_j \in \mathbb{F}_{2^m}$ can be represented as
\begin{equation}
\label{eq:f_y}
    F(y) = f_3y^3 + \sum_{i=0}^{\lceil (t-4)/5 \rceil} y^{5i}(f_{5i} + \sum_{j=0}^{3} f_{5i+2^j}y^{2^j})
\end{equation}
After that, we can summarize all the steps as Algorithm~\ref{alg:linearized}. The function ``generate($m$)'' refers to the generation of the elements in $\mathbb{F}_{2^m}$ using Gray codes, see \cite{savage1997survey} for more details about Gray codes.

Algorithm~\ref{alg:linearized} presents a countermeasure in the last steps of the algorithm, i.e., we added a dummy operation for blinding if $X[j]$ is a root of polynomial $F(x)$.

\begin{algorithm}[!ht]
 \KwData{$F(x)$ as a univariate polynomial over $\mathbb{F}_{2^m}$ with degree $t$ and $m$ as the extension field degree.}
 \KwResult{$R$ as a set of roots of $p(x)$.}
 $\ell^k_i \gets \emptyset$; $\ell_{is} \gets \emptyset$; $A^j_k \gets \emptyset$; $R \gets \emptyset$; $dummy \gets \emptyset$\;
 \If{$f_0  == 0$}{
 $R.append(0)$\;
 }
 \For{$i\leftarrow 0$ \KwTo $\lceil (t-4)/5 \rceil$}
 {
    $\ell_i(x) \gets 0$\;
    \For{$j\gets 0$ \KwTo $3$}{
      $\ell_i(x) \gets \ell_i(x) + f_{5i+2^j}x^{2^j}$\;
      }
    $\ell_{is}[i] \gets \ell_i(x)$\;
 }
 \For{$k\gets 0$ \KwTo $m-1$}{
    \For{$i\leftarrow 0$ \KwTo $\lceil (t-4)/5 \rceil$}
    {
        $\ell^k_i \gets \ell_{is}(\alpha^k)$\;
    }

 }
 $A^0_i \gets \emptyset$\;
 \For{$i\gets 0$ \KwTo $\lceil (t-4)/5 \rceil$}{
  $A^0_i \gets f_{5i}$\;
 }

 $X \gets \text{generate}(m)$\;
 \For{$j\gets 1$ \KwTo $2^m - 1$}{
    \For{$i\gets 0$ \KwTo $\lceil (t-4)/5 \rceil$}{
        $A \gets A^{j-1}_i$\;
        $A \gets A + \ell^{\delta(X[j], X[j-1])}_i$\;
        $A^j_i \gets A$\;
    }
 }
\For{$j\gets 1$ \KwTo $2^m - 1$}{
    $result \gets 0$\;
    \For{$i\gets 0$ \KwTo $\lceil (t-4)/5 \rceil$}{
        $result = result + (X[j])^{5i}A^j_i$\;
    }
    $eval = result + f_3(X[j])^{3}$\;
    \eIf{$eval == 0$}{
        $R.append(X[j])$\;
    }{
        $dummy.append(X[j])$\;
    }
}
\Return $R$\;
 \caption{Linearized polynomials for finding roots over $\mathbb{F}_{2^m}$.}
  \label{alg:linearized}
\end{algorithm}

\section{Successive Resultant Algorithm}
\section{Cantor-Zassenhaus Algorithm}
