In this Chapter, we present an overview of the needed concepts to better understanding of this thesis. First, we describe the main properties of Polynomials over finite fields. After, we present an overview of the coding theory. Explaining the main structures and the operations. At the end, we present the most important code for this works, which is the Goppa Codes, and we present and Literature reviews which the main works on root finding algorithm in code-based cryptosystems. 

\section{Algebraic structures}
The goal of this works relies on find a secure way to compute roots of an polynomial over a binary, and in this section we will define it and present the main characteristics of it.

\begin{definition}
Let $\mathbb{F}_{2}^{m}$ an finete field with size of $2n=^m$
\end{definition}{}

\section{Coding theory}
Coding theory is an engineerian area that focus on the data transmission. 

\subsection{Linear codes}
\begin{definition}
Let $\mathbb{F}_{2}^$
\end{definition}

\subsection{Goppa codes}
Let $m, n, t\in \mathbb{N}$. A binary Goppa code $\Gamma(L, g(z))$ is defined by a polynomial $g(z) = \sum_{i=0}^{t}g_iz^i$ over $\mathbb{F}_{2^m}$ with degree $t$ and supported by $L = (\alpha_1, \alpha_2, \dots, \alpha_n) \in \mathbb{F}_{2^m}$ with $\alpha_i \neq \alpha_j$ for $i\neq j$, such that $g(\alpha_i) \neq 0$ for all $\alpha_i \in L$ and $g(z)$ is square free. To a vector  $c = (c_1 \ldots, c_{n}) \in \mathbb{F}^n_{2}$ we associate a syndrome polynomial associate the syndrome polynomial
\begin{align}
  S_c(z) = \sum_{i=1}^{n} \frac{c_i}{z+\alpha_i},  
\end{align}
where ${z+\alpha_i}$ is invertible $\pmod{g(z)}$, i.e., $(z+\alpha_i) \times \frac{1}{z+\alpha_i} \equiv 1 \pmod{g(z)}$.
\begin{definition}
The binary Goppa code $\Gamma(L, g(z))$ consists of all vectors $c \in \mathbb{F}_{2}^n$ such that
\begin{equation}
    S_c(z) \equiv 0 \bmod{g(z)}.
\end{equation}
\end{definition}

% Change this
The parameters of a linear code are the size $n$, dimension $k$ and minimum distance $d$. We use the notation $[n,k,d]-$Goppa code for a binary Goppa code with parameters $n,k$ and $d$. If the polynomial $g(z)$ which defines a Goppa code is irreducible over $\mathbb{F}_{2^m}$, we call the code an irreducible Goppa code.

The length of a Goppa code is given by $n = |L|$ and its dimension is $k \geq n-mt$, where $t = deg(g)$, and the minimum distance of $\Gamma(L, g(z))$ is $d \geq 2t + 1$. The syndrome polynomial $S_c(z)$ can be written as:
\begin{equation}
    S_c(z) \equiv \frac{w(z)}{\sigma(z)} \mod g(z),
\end{equation}
where $\sigma(z) = {\displaystyle \prod_{i=1}^{l}(z+\alpha_i)}$ is the product over those $(z+\alpha_i)$ where there is an error in position $i$ of $c$. This polynomial $\sigma(z)$ is called Error-Locator Polynomial (ELP).

A binary Goppa code can correct a codeword $c \in \mathbb{F}_{2}^n$, obscured by an error vector $e \in \mathbb{F}_{2}^n$ with Hamming weight $w_h(e)$ up to $t$, i.e., the numbers of non-zero entries in $e$ is at most $t$. The way to correct errors is using a decoding algorithm. For irreducible binary Goppa codes we have three alternatives for that. The extended Euclidean Algorithm (EEA) and Berlekamp-Massey algorithm are out of the scope of this work, because they needed a parity-check matrix that has twice more rows then columns. The Patterson algorithm~\cite{patterson1975algebraic}, focus of this paper, can correct up to $t$ errors with a smaller structure.

\section{Cryptography primitives}
Maybe some idea of the public key cryptography and the association of a private key with a person. Relation with the fist elementary paper of Diffie and Hellman.
\subsection{Public-key cryptography}
Given the idea of Public Key crypto. The idea of signature with focus on authentication problem. The introduction on of KEM.
\subsection{Key encapsulation mechanisms}
Introduces the KEM and the key exchange. Why we use that, since AES it is better than RSA and DSS or something else.

\section{Side-channel attacks}
In summary, a side-channel attack is any type of attack when the attacker acquire sensitive information from the implementation of the cryptosystem. There are a several types of side-channel attacks, and almost of then requires a extensive knowledge over the target cryptosystem. Even the standard cryptography primitives, like the RSA~\cite{rivest1978method}, are susceptible to an side-channel attacks~\cite{kocher1996timing}.

Similarly the traditional cryptography, the quantum resistance cryptography are susceptible to most of the side-channel attacks. In case of the code-based cryptosystems, one of the most dangerous side-channel attack are based on the variance timing on the execution of the operations. This attack are called timing side-channel attack and a briefly idea are presented in~\ref{sub:timing-attack}

\subsection{Timing side-channel attacks}\label{sub:timing-attack}
A timing side-channel attack was an attack were an attacker are able to infer information from the time execution of a cryptography algorithm. To better understanding of how a timing side-channel attack works, we presents Example~\ref{example-timing}. 

\begin{example}\label{example-timing}
Let us suppose that an attacker has access to the time execution of a password validation (For instance we use an 4 digit password). This validation was made through the naive implementation presented in the Listings~\ref{lst:naive-pass}

\begin{lstlisting}[caption={Naive implementation of password check },label={lst:naive-pass},language=C]
//C
int passCheck(char * input_pass) {
    int i = 0;
    while (i < 4) {
        if (input_pass[i] == getPassAt(i)) {
            continue;
        } else {
            return -1;
        }
    }
    return 0;
}
\end{lstlisting}
So, an attacker with knowledge of the implementation, with access to the time wasted to verify a password could perform a simple attack, first  flipping the first char to all possible chars, and assume that the correct was that with spent more time. After repeat this for the all characters, the attacker recover the secret password.
\end{example}

We present this toy example to give an idea of how an attacker, who knows the implementation details are able to infer information about the execution time of an algorithm. In more complex cryptosystems this inference was not simple. However, it still possible to steel sensitive information measuring the decoding execution time.

The authors in~\cite{shoufan2009timing} presents the idea of infer information on the time variance when we flip a bit over a ciphertext. This idea becomes of the fact that if we flip a correct bit (i. e. a position were a error was added) the algorithm will have less errors to correct and will return early. The opposite occurs when we flip a wrong bit. Thus, the algorithm will return lately. This attack was base of the attack presented in Chapter~\ref{ch:code-based}.


\section{Literature review}
The decoding process of McEliece cryptosystem is the most sensitive part of the algorithm. The usage of the private key demands that this algorithm does not leak any information about the key, or even, any information about the error added to the message. The authors in \cite{bucerzan2017improved} shows that a time deviation on root finding process in the Patterson's decoding algorithm could open avenues for side-channel attacks. 

The direct way to find all roots of a polynomial is called exhaustive search. In summary, it just tests all possible elements and checks if it is a root. The authors in~\cite{strenzke2012fast} show an optimization to this approach. They divide the original polynomial when a root is found. This reduces the size of the polynomial and speeds up the exhaustive search in about ~30\%. Although this algorithm is efficient, it does not prevent side-channel attacks.

An alternative proposal to find roots was created by Berlekamp in 1970. The classical Berlekamp Trace Algorithm computes the roots of a polynomial in an efficient way~\cite{berlekamp1970factoring}. It was improved in~\cite{strenzke2012fast} by returning the recursion before the original algorithm. Another approach to compute roots was proposed in~\cite{fedorenko2002finding}, and was generalized in~\cite{Skachek2008,biswas2009}. However, all of these approaches do not present constant behavior, and consequently are susceptible to a side-channel attack.

More recently, the authors in~\cite{petit2014finding} present a different algorithm to compute the roots of a polynomial. Lately generalized in~\cite{petit2016finding}, the Successive Resultants Algorithm (SRA) is a efficient method, with a different approach to find roots in a polynomial over any finite field. Nevertheless, no analysis of execution time deviation was made.

All approaches presented in this Section was root finding techniques currently in use in code-based cryptosystems. Nonetheless, it was well know that one of the most efficiency method for computing roots over a polynomial was proposed by Cantor and Zassenhaus in 1981~\cite{cantor1981new}. Notwithstanding its efficiency, to the best of our knowledge, it wasn't used in any code-based cryptosystems. For this works, we will consider the usage of the Rabin approach, with has an adaptation for fields with odd characteristics.